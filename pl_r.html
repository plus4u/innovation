<!doctype html>
<title> R & Statistics </title>

<head>

  <meta charset="utf-8" >

  <link rel="stylesheet" href="topnavigation_style_01.css">
  <link rel="stylesheet" href="business_statistics_style_01.css">

</head>

<body>

  <top id="pageTop">

    <div class="navbar">
      <a href="home.html">Home</a>

      <div class="subnav">
        <button class="subnavbtn">Strategy <i class="fa fa-caret-down"></i></button>

        <div class="subnav-content">
          <a href="st_bm_innovation.html"> Business Model Innovation</a>
          <a href="st_pi_method.html"> Digital PI 방법론 </a>
          <a href="st_technique.html"> 기법 및 Tool </a>
        </div>

      </div>

      <div class="subnav">
        <button class="subnavbtn"> Operation Excellence <i class="fa fa-caret-down"></i></button>
        <div class="subnav-content">
          <a href="pi_process.html"> Process </a>
          <a href="pi_digital_factory.html"> Digital Factory </a>
          <a href="pi_system.html"> System & Solutions</a>
        </div>

      </div>
      <div class="subnav">
        <button class="subnavbtn">Data Analytics <i class="fa fa-caret-down"></i></button>
        <div class="subnav-content">
          <a href="da_business_statistics.html">Business Case with Statistics </a>
          <a href="da_machine_learning.html">Machine Learning</a>
          <a href="da_data_app.html"> 데이터 활용 Business-ML-R/Shiny</a>
        </div>
      </div>
      <div class="subnav">
        <button class="subnavbtn">Program Language <i class="fa fa-caret-down"></i></button>
        <div class="subnav-content">
          <a href="pl_python.html">Python TensorFlow Tensorboard</a>
          <a href="pl_r.html">R</a>
          <a href="pl_shiny.html">Shiny</a>
          <a href="pl_web_open_source.html">web system & Cloud</a>
        </div>
      </div>
      <a href="contact.html">Contact</a>
    </div>
  </top>

  <hea id="pageHeader">

    <h1> Program Language - R ( 제조업 프로세스에서 활용 )  </h1>

    <br>
    <br>
  </hea>

  <nav id="mainMenu">
    <ol>
      <li><a href="bm_business_model.html" > Data manipulation </a>
        <ul>  Data manipulation  </ul>
        <ul>  Matrix </ul>
        <ul>  Function  </ul>
        <ul>  For, while, If </ul>
        <ul>  . </ul>
        <br>
      </li>

      <li><a href="bm_pi_it.html" > Plot  </a>
        <ul> Build graph  </ul>
        <ul> Session  </ul>
        <ul> TensorBoard </ul>
        <ul> . </ul>
        <br>
      </li>

      <li><a href="#t.test" > Statistics   </a></li>
      <br>
      <br>

      <li><a href="#t.test" > t.test   </a></li>
      <ul> one sample </ul>
      <ul> paired sample </ul>
      <ul> two sample </ul>

      <li><a href="dab_anova.html" > ANOVA </a></li>
      <ul> one-way ANOVA </ul>
      <ul> two-way ANOVA </ul>
      <ul> MANOVA </ul>
      <ul> RM-ANOVA </ul>

      <li><a href="dt.html" > Reliability </a></li>
      <br>

      <li>PCA FA </li>
      <ul><a href="dab_pca.html" > PCA </a></ul>
      <ul><a href="dab_fa.html" > FA </a></ul>
      <br>

      <li><a href="dab_correlation.html" > Correlation </li>
        <ul> Pearson's correlation </ul>
        <ul> Spearman's correlation </ul>
        <ul><a href="" > 교차 분석 </a></ul>
        <ul><a href="" > 편상관 분석  </a></ul>

        <li><a href="dab_linear_regression.html" > Linear Regression </a></li>
        <ul><a href="" > Simple Linear Regression </a></ul>
        <ul><a href="" > Multiple Linear Regression </a></ul>
        <ul><a href="" > Dummy Linear Regression </a></ul>
        <ul><a href="" > Hierarchical analysis </a></ul>
        <ul><a href="" > Logistics Regression </a></ul>
        <ul><a href="" > Mediation Regressions </a></ul>
        <ul><a href="" > Logistics Regression </a></ul>
        <ul><a href="" > Moderator Regressions </a></ul>

        <li><a href="dab_discriminant.html" > Discriminant Analysis </a></li>

        <li><a href="dab_clustering.html" >Clustering Analysis </a></li>
        <ul> hierarchical Clustering </ul>
        <ul> k-means Clustering </a></ul>

        <li><a href="bm_pi_it.html" > Machine Learning   </a></li>
        <ul> .  </ul>
        <ul> . </a></ul>
        <ul> . </a></ul>
        <ul> . </a></ul>
        <br>


        <li><a href="#t.test" > 프로세스별 활용   </a></li>
        <br>
        <br>

        <li><a href="bm_pi_it.html" > Project Management  </a>
          <ul> Project Management </ul>
          <ul> Risk & Communication </ul>
          <ul> Contract </ul>
          <ul> Schedule </ul>
          <ul> Cost Management </ul>
          <ul> 국제 계약 </ul>
        </li>

        <li><a href="bm_pi_it.html" >  E2E Process - Basic  </a></li>
        <ul> Order to Cash </ul>
        <ul> Procure to Pay </ul>
        <ul> Plan to Produce </ul>
        <ul> Design to Deploy </ul>
        <ul> Inspect to Quality </ul>
        <ul> Inbound to Outbound </ul>
        <ul> Project to Decommission </ul>

        <li><a href="bm_pi_it.html" >  E2E Process - Core  </a></li>
        <ul> Forecasting from Big Data </ul>
        <ul> Optimization from entire </ul>
        <ul> Use of outbound resources </ul>

        <li><a href="bm_pi_it.html" >  Engineering  </a>
          <ul> 신뢰성 </ul>
          <ul> .. </ul>
          <ul>.. </ul>
        </li>

        <li><a href="bm_pi_it.html" >  Procurement  </a>
          <ul> Partner </ul>
          <ul> .. </ul>
          <ul>.. </ul>
        </li>

        <li><a href="bm_pi_it.html" >  Manufacturing  </a>
          <ul> Efficiency </ul>
          <ul> 제품과 서비스의 조달 </ul>
          <ul>.. </ul>
        </li>

      </ol>

      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>
      <br>

    </ol>


  </nav>
  <des id="pageDes">
    <h3> R 은 통계분석을 위한 아주 유용한 Open source 프로그램이다. 배우기도 용이하고 무엇보다 Open source 프로그램 이기에 비용 부담도 없다는 것이다.
      제조기업 현장에서 통계분석이 필요한 여러가지 상황에서 사용할 수 있는 방법을 제시하고자 한다.   </h3>
      <img src="image_pl_r.png" width="1000" height="350">
      <p> image source : https://statkclee.github.io/data-science/data-science-library.html </p>

    </des>



    <lef id="subLef">

      <h2> Data manipulation </h2>
      <p>
      </p>
      <ul>
        <li> R 설치 : https://www.r-project.org/ </li>
        <li> 개발도구 : RStudio : https://www.rstudio.com/ </li>
        <li> 개발도구 : atom :  https://atom.io/  </li>
        <li> Data type   </li>
        <li> 수와 계산 :  </li>
        <li> 변수 :  </li>
        <li> 주석 처리 :  </li>
        <li> data.frame, matrix :

          row.names(df2) </br>

          data.matrix() </br>


          # read.table(), read.csv() </br>
          # list -> data.frame  </br>

          data.frame(list_x) </br>

          a <- data.frame(1:3, 11:13) </br>

          a$X1.3 </br>

          grep(2,a[,2]) </br>


          grep("X1.3",colnames(a)) </br>

          names(a) </br>

          names(a) <- c("hd1", "hd2") </br>

          names(a)[names(a)=="hd1"] <- c("newhd") </br>

          a$newcol <- NA </br>

          a$badcol <- NULL </br>

          subset(a, select = -newcol) </br>

          cbind, rbind </br>

          do.call(rbind, mylist) </br>


          merge (df1, df2, by = intersect(names(df1),names(df2))) </li>

          <li> Data type : list </br>
            no <- c(1:3) </br>
            name <- c("a", "b", "c") </br>
            weight <- c(50, 60, 70) </br>

            df1 <- data.frame(no, name, weight) </br>

            list_x <- list(x, df1) </br>

            list_y <- list(me=c(1:3), sd =0.5, center=0) </br>
            list_y$me[2] </br>
            list_y$me[-c(2,3)] </br>

            list_y <- list(list_y, list_x) </br>

            emty_list <- list.files("./var1/") </br>

            filenames <- sapply(emty_list,list) </br>
            # Foreach ,     # .final </br>

            # compare data.frame </br>

            tem <- 1:3 </br>

            names(tem) <-  c("hd1", "hd2", "hd3") </br>

            mode(tem) </br>

            df2 <- data.frame(x=1:3, y=c("aa","bb","cc")) </br>
            mode(df2) </br>

            append(list_x, list(x=10, y=20)) </br>


            append(list_x, list(f=1:5), after=0) </br>

          </li>
          <li> 수와 계산 :  </li>
          <li> 변수 :  </li>


          <li> 제어 & Function </li>
          비교와 블리언 </br>
          조건문 </br>
          입력과 출력 </br>
          논리 연산 </br>
          Cheat Sheet
          컨테이너와 반복문 </br>

          <li> Plot </li>
          Bart chart </br>
          . Histogram </br>
          . Scree Chart </br>
          . Histogram </br>
          모듈 </br>
          <li> 객체 지향 프로그래밍 </li>
        </ul>


      </lef>

      <mid id="subMid">

        <h2> 통계 분석 </h2>
        <p> code 참조 : github
        </p>
        <ul>
          <li> Basics </li>
          x <- 1:10  # mean(x) # sd(x) # var(x) </br>

          <li>  t.test </li>
          ..... </br>

          <li>one sample </li>
          ..... </br>

          <li>paired sample </li>
          ..... </br>

          <li>two-way ANOVA </li>
          ..... </br>

          <li>MANOVA </li>
          ..... </br>

          <li>RM-ANOVA </li>
          ..... </br>
          <li>Reliability </li>
          alpha(Q)  </br>
          <li>PCA </li>
          .. </br>
          prcomp( ) </br>
          <li>FA </li>
          ..... </br>
          ..... </br>
          <li> Correlation </li>
          Spearman's correlation </br>
          독립성 분석 :  </br>
          동질성 분석 : </br>
          적합도 분석 </br>
          ..... </br>
          <li> 편상관 분석 </li>
          ..... </br>
          ..... </br>
          <li>  Simple Linear Regression </li>
          ..... </br>
          <li>    Multiple Linear Regression  </li>
          Dummy Linear Regression </br>
          Hierarchical analysis </br>
          Logistics Regression </br>
          Mediation Regressions </br>
          Moderator Regressions </br>
          <li>  Logistic classification </li>
          aod : wald.test </br>
          glm(~ , family="binomial")  </br>

          <li>  Discriminant analysis  </li>
          lda( y ~ . , ...   ) </br>
          prior ; 사전확률 </br>
          predict(~ ,  )  </br>

          <li>clu <- hclust(dist(iris[, 3:4])) </br>
            plot(clu) </br>
            clu_cut <- cutree(clu, 3)   </br>
            table(clu_cut, iris$Species) </br>

            plot  </br>   </li>

            <li> kmeans : library(caret)  </br>

              train, test datase split </br>
              training_data <- scale(training[-5]) </br>
              kmeans(training_data[,-5], centers = 3, iter.max = 10000) </br>

              table(training$Species, training$cluster) </br>

            </li>

            <li> </li>
            <li>  non-parametric </br>
              #1. wilcox.test / paired = FALSE </br>

              A <- c(71, 78, 79, 71, 86, 81, 92) </br>

              B <- c(73, 79, 81, 74, 97, 88, 99) </br>

              wilcox.test(A, B, paired = FALSE, alternative = "two.sided", mu = 0.0,
              exact = TRUE, correct = TRUE, conf.int = TRUE, conf.level = 0.95) </br>

              #  W = 17, p-value = 0.1848   //two.sided p-value = 0.3695 </br>


              wilcox.test(A, B, paired = T, alternative = "two.sided", mu = 0.0,
              exact = TRUE, correct = TRUE, conf.int = TRUE, conf.level = 0.95) </br>

              # less      -> V = 0, p-value = 0.01101 </br>
              # two.sided -> V = 0, p-value = 0.02201 </br>


              ## 2. mann whitney </br>

              x <- c(5.7 , 6.3 ,6.4, 6.5 ,7.8 , 8.6, 9.8, 10.2 ) </br>

              y <- c(3.8 , 4.3 , 5.6 , 5.7, 6.3 , 6.6 , 6.8 , 7.1 , 8.4 ) </br>

              wilcox.test(x, y, paired = F, alternative = "two.sided", conf.level = 0.95) </br>

              # two.sided   W = 53, p-value = 0.1119  </br>

              wilcox.test(x, y, correct=FALSE)   # W = 53, p-value = 0.1015 </br>


              # PLOT </br>

              ab <- data.frame(a,b) </br>

              boxplot(a,b)  </br> </li>


            </ul>
          </mid>

          <rig id="subRig">

            <h2> 프로세스별 활용 </h2>
            <p>
            </p>
            <ul>
              <li> Project Management </li>
              . schedule : . </br>
              . cost : . </br>
              . risk : . </br>

              <li>  Engineering </li>
              . DTC..... </br>

              <li> Procurement </li>
              . PSM.... </br>

              <li> Manufacturing </li>
              . EOQ.. </br>
              . EPQ.. </br>
              . EOQ.. </br>
              . EOQ.. </br>

              <li> Quality </li>
              ..... </br>

              <li>MANOVA </li>
              ..... </br>

              <li>RM-ANOVA </li>
              ..... </br>
              <li>Reliability </li>
              ..... </br>
              <li>PCA FA </li>
              ..... </br>
              <li>PCA </li>
              ..... </br>

            </ul>

          </rig>



          <bot id="subBot">


            <h2> Data type </h2>
            <p>   </p>
            <ul>
              <li> Data type : vector, data frame, matrix(array), factor, list </li>
              <li> 자료형 확인 및 정의 : as.character(x),        as.complex(x) ,  as.numeric(x) or as.double(x),
                as.integer(x),   as.logical(x)  </li>
                <li> vector :   백터는 동질적dls 같은 자료형으로 같은 모드를 가지고 있어야 한다. 하나의 값으로 구성된 백터가 스칼라이고
                  여러개 있으면 벡터 </li>
                  <li> data frame : 데이터를 열을 기준으로 정리한 것으로 표 형태의 데이터를 표현하기 위함이다.

                    행은 모두 같은 길이이며, 열은 하나의 엘리먼트를 나타낸다. 행렬과 다른점은 각각의 행들이 서로다른 데이터 타입들을 가질 수 있다는 것이다.
                    즉, 각각의 열들은 같은 타입으로 이뤄지지만, 모든 열이 모두 같을 필요는 없다.
                    data.matrix() : 행렬을 data frame으로 변경 할 수 있다.
                    데이터 프레임 합치기는 cbind # 두개의 데이터를 열로 쌓고, rbind # 두개의 데이터를 행으로 쌓는다. </li>
                    <li> matrix(array) : vector 에 차원을 정해준 것이 바로 Matrix이다. 백터의 dim 속성이 처음엔 NULL 이지만 이것을 주게 되면 matrix가 된다.

                      dim(2,3) # 2 by 3 행렬 /

                      Array (배열)

                      3차원 matrix 부터는 배열이라는 이름을 쓴다. </li>

                      <li> Factor(요인) : 요인들은 간단하고 효율적인 형태로 데이터 프레임에 저장되어 특별한 속성이 있다.       R은 백터에 있는 고유한 값(unique value)의 정보를 얻어 내는데, 이 고유 값들을 요인의 '수준(level)'이라고 일컫는다.
                        요인의 범주형 변수 기능으로, 분할표, 선형 회귀, 변량 분석, 로지스틱 회귀 분석에 사용 된다.
                        집단 분류 기능은 데이터 항목에 라벨을 붙이거나 태깅을 할 때 쓰는 방법이다.factor( x, levels, ordered #TRUE=순서형, FALSE=명목형 데이터) /  nlevels(x) / 중간에 값 넣기 ;
                        factor(append(as.character(gender),"TRUE"))
                      </li>

                      <li> list : 이질적인 다양한 자료형을 포함 할수 있다.

                        연속적인 리스트라면,  do.call(rbind,mylist) 이용 모두 행열이 같은 크기일때만 가능하다.

                        서로다른 데이터 프레임 합치기는  merge 일치하는 부분만 합치고 싶으면,      merge(A,B, by="열 이름")

                        으로 설정한다.  </li>   </ul>



                        <h2> 요인 분석 </h2>
                        <p> 주성분 분석과 공통요인 분석으로 구분된다.  </p>
                        <ul>
                          <li> 주성분 분석 :
                            <p> #1. multicollinearity check : cor(iris[1:4]) ; # some of them are big as 0.87 </p>

                            <p> # 2. biased data -> transform log / log_ir <- log(iris[, 1:4])
                              데이터가 편향된 경우 사용 (skip도 가능)  /  ir_species <- iris[,5] </p>

                              <p> # 3. pca analysis : # Unlike princomp, prcomp : variances are computed with the usual divisor N - 1.

                                ir_pca <- prcomp(log_ir, center = T, scale. = T) </p>

                                <p> train, test dataset 으로 구분하여 성능 확인도 가능 </p>

                                <p> # 4. plot scree graph : plot(ir_pca,type="lines") </p>

                                <p> # 5. summary : check that how much it has a power of explanation Cumulative Proportion

                                  summary(ir_pca)/    # Cumulative Proportion  0.7331 of PC1,  0.9599 with PC2 </p>

                                  <p> # 6. linear regression : prc <- as.matrix(log_ir) %*% ir_pca$rotation # skip 가능 </p>


                                  <p> # 7.     , train <- cbind(ir_species,as.data.frame(prc))

                                    train[,1] <- as.factor(train[,1]) / colnames(train)[1] <- "label" </p>

                                    <p> # 8. linear regression with PC1, PC2 / fit <- lm(label~PC1+PC2, data=train) </p>

                                    <p> # 9. performance check  /  fit_pred <- predict(fit, newdata = train) </p>

                                    <p> # 10. comparision the both prediction, actual  /  b <- round(fit_pred)

                                      b[b==1] <- "setosa"  /  b[b==2] <- "Versicolor"  / b[b==3] <- "Virginica"  </p>

                                      <p> a <- ir_species  / table(b,a) </p>  </li>

                                      <li>   </li>
                                      <li>   </li>
                                    </ul>

                                    <h2> 신뢰도 분석 </h2>
                                    <p>   </p>
                                    <ul>
                                      <li>  </li>
                                      <li>   </li>
                                      <li>   </li>

                                      <p>      # 1. data :  Q <- data.frame(
                                        Q1=c(1,4,2,3,4,2,3,4,3,2),
                                        Q2=c(2,4,1,2,4,1,2,5,2,1),
                                        Q3=c(2,5,1,3,3,2,3,4,2,2))

                                        pairs(Q, panel=panel.smooth) </p>

                                        <p> # 2. cronbach :  alpha () :  library(psy) /  cronbach(Q) :  library(psych) /

                                          a <- alpha(Q) /  a$total / View(a$scores)

                                        </ul>



                                        <h2> Correlation </h2>
                                        <p>   </p>
                                        <ul>
                                          <li> Spearman's correlation </li>
                                          <li> 독립성 분석 :   </li>
                                          <li> 동질성 분석 :  </li>
                                          <li> 적합도 분석 </li>

                                          <p>    ### correlation : # 1.
                                            aq <- airquality[,c(1:4)] /

                                            cor(aq) /

                                            aq2 <- na.omit(aq) /

                                            cor(aq2) /

                                            plot(aq2) /

                                            pairs(aq2, panel=panel.smooth)   </p>


                                            <p>    # 2.  library(PerformanceAnalytics) /    chart.Correlation(aq2, histogram=TRUE, pch=19)
                                            </p>

                                            <p>  # 3.    library(corrplot) /

                                              aq.cor <- cor(aq2) /    corrplot(aq.cor, method="number")   </p>


                                              <p>      ##    1. goodness of fit test : chisq.test() /

                                                obs <- c(19, 40, 35) /

                                                prob <- c(2/10, 3/10, 5/10) /  chisq.test(obs, p=prob)   </p>

                                                <p>    ## indexing / chisq.test() of data from data frame /

                                                  # chisq.test() of data from data frame /

                                                  data(Cars93, package="MASS") /

                                                  Car_Type <- table(Cars93$Type)   </p>

                                                  <p>  #  Car_Type_Prob <- c(0.2, 0.1, 0.2, 0.2, 0.2, 0.1) /

                                                    chisq.test(x=Car_Type, p=Car_Type_Prob)   </p>



                                                    <p>     ## b.  test of independence  /   # data key-in way 1 : rbind()

                                                      row_1 <- c(7, 13, 9, 12) /
                                                      row_2 <- c(13, 21, 10, 19) /
                                                      row_3 <- c(11, 18, 12, 13) /

                                                      data_rbind <- rbind(row_1, row_2, row_3)   </p>


                                                      <p>     # data key-in way 2 : matrix() /
                                                        raw_data <- c(7, 13, 9, 12, 13, 21, 10, 19, 11, 18, 12, 13) /
                                                        dt <- matrix(raw_data, byrow=TRUE, nrow=3)   </p>

                                                        <p>    # giving names to the rows and columns of the data table : dimnames()

                                                          /  dimnames(dt) <- list("Class" = c("Class_1", "Class_2", "Class_3"),
                                                          "Score" = c("Score_H", "Score_M", "Score_L", "Fail"))

                                                        </p>

                                                        <p>     ## exploratory data analysis /
                                                          # marginal distribution : addmargins() /
                                                          addmargins(dt) /     prop.table(dt)   </p>

                                                          <p>   addmargins(prop.table(dt)) /       # bar plot :   barplot(t(dt), beside=TRUE, legend=TRUE,
                                                            ylim=c(0, 30),
                                                            ylab="Observed frequencies in sample",
                                                            main="Frequency of math score by class")   </p>

                                                            <p>      # indexing statistics of chisq.test() /

                                                              fit <- chisq.test(dt) /

                                                              fit$observed # observed frequency /

                                                              fit$expected # expected frequeycy /

                                                              fit$residuals # residual between observed and expected frequecy /

                                                              fit$statistic # chi-squared statistics /

                                                              fit$parameter # degrees of freedomfit /

                                                              fit$p.value # P-value   </p>

                                                              <p>         ## c. test of homogeneity  :

                                                                raw_data <- c(10, 20, 30, 10, 40, 30) /
                                                                dt <- matrix(raw_data, byrow=TRUE, nrow=2)  /  # giving names :
                                                                dimnames(dt) <- list("Gender" = c("f", "m"), "par" = c("aa", "bb", "cc"))   </p>

                                                                <p>      ## exploratory data analysis

                                                                  # marginal distribution : addmargins()
                                                                  addmargins(dt)

                                                                  # proportional distribution : prop.table()
                                                                  prop.table(dt)

                                                                  addmargins(prop.table(dt))   </p>

                                                                  <p>      # bar plot :    barplot(t(dt), beside=TRUE, legend=TRUE, ylim=c(0, 120),
                                                                    ylab="Observed frequencies ",
                                                                    main="Parament preferences by gender")   </p>

                                                                    <p>    ## chisquared test :    chisq.test(dt)

                                                                      # indexing statistics of chisq.test() /
                                                                      fit <- chisq.test(dt)  /

                                                                      fit$observed # observed frequency /

                                                                      fit$expected # expected frequeycy /

                                                                      fit$residuals # residual between observed and expected frequecy /

                                                                      fit$statistic # chi-squared statistics /

                                                                      fit$parameter # degrees of freedomfit /

                                                                      fit$p.value   </p>

                                                                    </br>

                                                                  </ul>


                                                                  <h2> Multinomial variables Regression</h2>
                                                                  <p>   </p>
                                                                  <ul>
                                                                    <li>  </li>
                                                                    <li>   </li>
                                                                    <li>   </li>
                                                                  </ul>


                                                                  <h2> Logistic classification   </h2>
                                                                  <p> 이분 분류형에 대한    </p>
                                                                  <ul>
                                                                    <li>  </li>

                                                                    <p>    ### logistics regression :      # ready : xtabs :

                                                                      d <- data.frame(x=c("1", "2", "2", "1"),
                                                                      y=c("A", "B", "A", "B"),
                                                                      num=c(3, 5, 8, 7)) </br> xtabs(num ~ x + y, data=d) </p>
                                                                      <p>    # 1.    library(ggplot2)

                                                                        mydata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv") </p>

                                                                        <p>  sapply(mydata, sd)  /    # contingency table : xtabs(~ x + y, data)

                                                                          xtabs(~admit+rank, data=mydata) </p>


                                                                          <p>    # factor :      mydata$rank <- factor(mydata$rank)

                                                                            mylogit <- glm(admit ~ gre + gpa + rank, data = mydata, family = "binomial")

                                                                            summary(mylogit) </p>


                                                                            <p>  ## aod  :   walt.test /     library(aod)

                                                                              wald.test(b = coef(mylogit), Sigma = vcov(mylogit), Terms = 4:6) </p>

                                                                              <p>     # OR 비 :  exp(coef(mylogit)) /
                                                                                newdata1 <- with(mydata, data.frame(gre = mean(gre), gpa = mean(gpa), rank = factor(1:4))) </p>

                                                                                <p>  # rank, gpa 고정후 :      newdata2 <- with(mydata, data.frame(gre = rep(seq(from = 200, to = 800, length.out = 100),
                                                                                  4), gpa = mean(gpa), rank = factor(rep(1:4, each = 100))))
                                                                                </p>

                                                                                <p>  # rank : newdata3 <- cbind(newdata2, predict(mylogit, newdata = newdata2, type = "link",
                                                                                  se = TRUE))
                                                                                  newdata3 <- within(newdata3, {
                                                                                    PredictedProb <- plogis(fit)
                                                                                    LL <- plogis(fit - (1.96 * se.fit))
                                                                                    UL <- plogis(fit + (1.96 * se.fit))
                                                                                  }) </p>

                                                                                  <p>        ggplot(newdata3, aes(x = gre, y = PredictedProb),
                                                                                    geom_ribbon(aes(ymin = LL, ymax = UL, fill = rank),alpha = 0.2), geom_line(aes(colour = rank)))

                                                                                    ggplot(newdata3, aes(x = gre, y = PredictedProb)) </p>
                                                                                    <li><a href="https://stats.idre.ucla.edu/r/dae/logit-regression/"> reference site </a> </li>




                                                                                  </ul>
                                                                                  <h2> Discriminant analysis </h2>
                                                                                  <p> 판별분석은 집단으로 구분되는 종속변수와 독립변수를 가지고 하는 분석   </p>
                                                                                  <ul>
                                                                                    <li> 1. dataset :   </li>
                                                                                    <li> 2. 분석 :   </br>

                                                                                      <p>    ###   1. dataset :  set.seed(123)

                                                                                        aa_length <- sample(seq(15,22.5,by=0.5), 50, replace=T)
                                                                                        aa_weight <- sample(seq(0.2,0.8,by=0.05), 50, replace=T)
                                                                                        bb_length <- sample(seq(46,61,by=0.5), 50, replace=T)
                                                                                        bb_weight <- sample(seq(1.36,3.2,by=0.5), 50, replace=T)
                                                                                        cc_length <- sample(seq(30,75.5,by=1), 50, replace=T)
                                                                                        cc_weight <- sample(seq(0.2,3.5,by=0.1), 50, replace=T)
                                                                                        dd_length <- sample(seq(25,38,by=0.5), 50, replace=T)
                                                                                        dd_weight <- sample(seq(0.4,0.54,by=0.01), 50, replace=T)
                                                                                        ee_length <- sample(seq(22,55,by=0.5), 50, replace=T)
                                                                                        ee_weight <- sample(seq(0.68,1.8,by=0.01), 50, replace=T)

                                                                                        length <- c(aa_length, bb_length, cc_length, dd_length, ee_length)
                                                                                        weight <- c(aa_weight, bb_weight, cc_weight, dd_weight, ee_weight)
                                                                                        speed <- rnorm(50*5, 7.2, sd=1.8)  </p>

                                                                                        <p>  fish <- c(rep("aa",50), rep("bb", 50), rep("cc", 50), rep("dd", 50), rep("ee", 50))
                                                                                          fish_data <- data.frame(length, weight, speed, fish) </p>

                                                                                          <p>  ## 2. lda :    library(MASS) /
                                                                                            fish_lda <- lda(fish ~., data=fish_data, prior=c(1,1,1,1,1)/5) /

                                                                                            fish.lda$counts </p>
                                                                                            <p>   set.seed(123) /
                                                                                              train100 <- sample(1:nrow(fish_data),100)
                                                                                              table(fish_data$fish[train100])



                                                                                              fish100_lda <- lda(fish ~., data=fish_data, prior=c(1,1,1,1,1)/5, subset=train100) </p>


                                                                                              <p>     ## predict() :    predict_fish100 <- predict(fish100_lda)
                                                                                                table(fish_data$fish[train100], predict_fish100$class) </p>


                                                                                                <p>     # ggplot() : library(ggplot2)

                                                                                                  p <- ggplot(as.data.frame(predict_fish100$x), aes(x=LD1, y=LD2, col-fish_data$fish[train100]))
                                                                                                  p <- p + geom_point() + geom_text(aes(label=as.character(predict_fish100$class)))
                                                                                                  # Adjust legend size
                                                                                                  p <- p + theme(legend.title=element_blank(), legend.text=element_text(size=20, face="bold"))
                                                                                                  # Adjust axis labels
                                                                                                  p <- p + theme(axis.title=element_text(face="bold", size=20), axis.text=element_text(size=18))
                                                                                                  # Display plot </p>

                                                                                                  <p>  ##  misclassficaiotn rate :  predict_new <- predict(fish100_lda, newdata=fish_data[-train100,])
                                                                                                    table(fish_data$fish[-train100], predict_new$class) /
                                                                                                    tab <- table(fish_data$fish[-train100], predict_new$class) </p>
                                                                                                    <p>   ## error rate /    tab_sum <- 1-sum(diag(tab))/sum(tab) </p>

                                                                                                    <li><a href="https://statkclee.github.io/data-science/data-science-library.html"> reference site </a> </li>


                                                                                                  </ul>

                                                                                                  <h2> Clustering : Hierarchical & kmeans </h2>
                                                                                                  <p> 비지도 학습으로 계층적 방식과, k-means 방식이 있으며, 크게 절차는 데이터 준비, 분석, 예측 및 성능 검증으로 이루어 진다. </p>
                                                                                                  <ul>
                                                                                                    <li> hierarchical clustering algorithm : </br>

                                                                                                      <p> ## a : hierarchical clustering algorithm ,  clu <- hclust(dist(iris[, 3:4])) /     plot(clu) </p>
                                                                                                      <p>       # generates the following dendrogram:    clu_cut <- cutree(clu, 3) # cut off the tree at the desired
                                                                                                        number of clusters using cutree   </p>
                                                                                                        <p>     #      table(clu_cut, iris$Species)    </p>
                                                                                                        <p>  # plot :    ggplot(iris, aes(Petal.Length, Petal.Width, color = iris$Species)) +
                                                                                                          geom_point(alpha = 0.4, size = 3.5) + geom_point(col = clu_cut) +
                                                                                                          scale_color_manual(values = c('black', 'red', 'green'))   </p>

                                                                                                          <p>      ## b : kmeans :  library(caret)  /       et.seed(123) /    train <- createDataPartition(y = iris$Species, p = 0.7, list = F)
                                                                                                          </P>

                                                                                                          <P>    training <- iris[train,]  /    testing <- iris[-train,] /  training_data <- scale(training[-5])
                                                                                                            /  summary(training_data)   </p>

                                                                                                            <p>  iris_kmeans <- kmeans(training_data[,-5], centers = 3, iter.max = 10000) /    iris_kmeans$centers   </p>
                                                                                                            <p> ##      /    training$cluster <- as.factor(iris_kmeans$cluster) /    qplot(Petal.Width, Petal.Length, colour = cluster, data = training)

                                                                                                              table(training$Species, training$cluster)   </p>
                                                                                                              <p>  ## 적절한 군집의 수 결정 : NbClust or sum of squares /    library(NbClust) /

                                                                                                                nc <- NbClust(training.data, min.nc = 2, max.nc = 15, method = "kmeans")   </p>

                                                                                                                <p> ## Some of square means /  wssplot <- function(data, nc = 15, seed = 1234) {
                                                                                                                  wss <- (nrow(data) - 1) * sum(apply(data, 2, var))
                                                                                                                  for (i in 2:nc) {
                                                                                                                    set.seed(seed)
                                                                                                                    wss[i] <- sum(kmeans(data, centers=i)$withinss)}
                                                                                                                    plot(1:nc, wss, type="b", xlab = "Number of Clusters",
                                                                                                                    ylab = "Within groups sum of squares")}  /     wssplot(training_data)   </p>


                                                                                                                    <p>  ## training :  training_data <- as.data.frame(training_data)

                                                                                                                      ## e1071 package
                                                                                                                      install.packages('e1071', dependencies=TRUE)

                                                                                                                      fit <- train(x = training_data[,-5], y = training$cluster,  method = "rpart")

                                                                                                                      testing_data <- as.data.frame(scale(testing[-5]))
                                                                                                                      testing_data_pred <- predict(fit, testing_data)

                                                                                                                      table(testing_data_pred ,testing$Species)   </p>

                                                                                                                    </li>
                                                                                                                    <li>   </li>
                                                                                                                    <li>   </li>
                                                                                                                  </ul>

                                                                                                                  <h2>Theory, Tool & Template</h2>
                                                                                                                  <p>
                                                                                                                  </p>
                                                                                                                  <ul>
                                                                                                                    <li>Theory :  </li>
                                                                                                                    <li>Tool : 조사분석, 통계, Digital Transformation, Process Innovation, Solution,    </li>
                                                                                                                    <li>기존 데이터 분석 : 각종 통계기법 (t.test, anova, 요인분석, 상관분석, 회귀분석, 판별분석, 군집분석), Machine learning </li>
                                                                                                                    <li>새로운 데이터 확보 : 조사기획, 데이터 확보, 분석 및 시사점 도출 </li>
                                                                                                                    <li>Template  </li>
                                                                                                                    <li>Reference Site </li>
                                                                                                                  </ul><p> DT, Process, Solution 관리해야 할 대상 도출


                                                                                                                    계획대비 실적의 수준을 벗어나 이러한 결과에 대한 여러가지 통계 기법과 머신러닝 솔루션을 통하여 현상을 보다 객관적으로 진단하고,
                                                                                                                    이러한 현상이 지속될 경우 어떠한 결과가 예측되는 지를 분석하며 그러한 문제가 어디에서 발생하고 있는지와 무엇을 관리해야 하는 지를
                                                                                                                    직관이 아닌 데이터 분석을 통하여 도출할 수 있다. 이후에 이러한 내용을 기반으로 혁신에 활용한다.

                                                                                                                  </p>

                                                                                                                </bot>

                                                                                                              </body>

                                                                                                              </html>
