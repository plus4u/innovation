<!doctype html>
<title> Business case of statistics technique & data analytics</title>

<head>

  <meta charset="utf-8" >

  <link rel="stylesheet" href="topnavigation_style_01.css">
  <link rel="stylesheet" href="business_statistics_style_01.css">

</head>

<body>

  <top id="pageTop">

    <div class="navbar">
      <a href="home.html">Home</a>

      <div class="subnav">
        <button class="subnavbtn">Strategy <i class="fa fa-caret-down"></i></button>

        <div class="subnav-content">
          <a href="st_bm_innovation.html"> Business Model Innovation</a>
          <a href="st_pi_method.html"> Digital PI 방법론 </a>
          <a href="st_technique.html"> 기법 및 Tool </a>
        </div>

      </div>

      <div class="subnav">
        <button class="subnavbtn"> Operation Excellence <i class="fa fa-caret-down"></i></button>
        <div class="subnav-content">
          <a href="pi_process.html"> Process </a>
          <a href="pi_digital_factory.html"> Digital Factory </a>
          <a href="pi_system.html"> System & Solutions</a>
        </div>

      </div>
      <div class="subnav">
        <button class="subnavbtn">Data Analytics <i class="fa fa-caret-down"></i></button>
        <div class="subnav-content">
          <a href="da_business_statistics.html">Business Case with Statistics </a>
          <a href="da_machine_learning.html">Machine Learning</a>
          <a href="da_data_app.html"> 데이터 활용 Business-ML-R/Shiny</a>
        </div>
      </div>
      <div class="subnav">
        <button class="subnavbtn">Program Language <i class="fa fa-caret-down"></i></button>
        <div class="subnav-content">
          <a href="pl_python.html">Python TensorFlow Tensorboard</a>
          <a href="pl_r.html">R</a>
          <a href="pl_shiny.html">Shiny</a>
          <a href="pl_web_open_source.html">web system & Cloud</a>
        </div>
      </div>
      <a href="contact.html">Contact</a>
    </div>
  </top>


  <hea id="pageHeader">

    <h1> Data Analytics - Business case of statistics technique & data analytics </h1>

    <br>
    <br>
  </hea>

  <nav id="mainMenu">

    <ol>

      <li><a href="dab_t.test_sample.html"> 통계 분석 </a></li>
      <ul> . t 검정 </ul>
      <ul> . 분산 분석 </ul>
      <ul> . 타당성과 신뢰성 </ul>
      <ul> . 요인 분석 </ul>
      <ul> . 신뢰도 분석 </ul>
      <ul> . 회귀분석 </ul>
      <ul> . 로지스틱 회귀분석 </ul>
      <ul> . 판별 분석 </ul>
      <ul> . 군집 분석 </ul>
      <ul> . 비모수 검정 </ul>
    </br>

    <li><a href="dab_anova.html" > 개념 </a></li>
    <ul> . 확률 </ul>
    <ul> . 분포 </ul>
    <ul> . 기술 통계 </ul>
    <ul> . 가설 검정 </ul>
    <ul> . 사후 분석 </ul>
    <ul> . 다중 공선성 </ul>
    <ul> . KMO, Bartlett </ul>
    <ul> . 요인 회전 </ul>
    <ul> . 공차와 VIF </ul>
  </br>

  <li><a href="dt.html" > Data Mining </a></li>
  <ul> . KDD </ul>
  <ul> . Machine learning과 관계 </ul>
  <ul> . Data Mining </ul>


</ol>

</nav>

<des id="pageDes">

<h3> 통계분석 기법을 기존 업무에 활용하여 새로운 가치를 얻을 수 있는 방법이 많음에도 기업에선 6 시그마 이후에 너무
  어렵게 접근하는 것 같아, 그 것에 대한 대안을 제시하고자 한다. </h3>


  <p> 통계가 제조 기업에서 중요한 이유 :       </p>

  <p> 프로세스별 기업 차원에서 사용 가능한 부분 :       </p>

  <p> 그런데 왜 잘 사용되지 않는가 ? :    </p>

  통계-ML-R/Shiny 활용 가능한 부분 :
  <br>
  <br>
</des>

<lef id="subLef">

  <h2> 주요 개념 </h2>

  <li> 확률,  </li>
  <li> 정규분포, 베르누이 분포 </li>
  <li> 이항분포, 프와송 분포 </li>
  <li> 기술통계 : 평균, 분산 및 표준편차  </li>
  <li> 가설검정 : 평균, 분산, 비율  </li>
  <li> 정규성, 독립성, 적합성 검정  </li>
  <li> 공분산, 상관분석 </li>
  <li> 상관분석 : Pearson, Spearman, 교차, 편상관 </li>
  <li> 우도비 </li>

</lef>

<mid id="subMid">

  <h2> 일표본, 분산분석, 요인분석 </h2>


  <li> 일표본 t 검정 : 검정변수 선택, 검정값 결정 </li>
  <li> ANOVA : 독립변수가 3개 이상 </li>
  <li> ANCOVA, RM-ANOVA, 혼합모형 </li>
  <li> 요인분석 : PCA, FA </li>
  <li> 요인회전, 상관행렬/공통성, </li>
  <li> 설명된 총분산, 요인적재값, 스크리 도표, </li>
  <li> 성분행렬 / 회전된 성분행렬, </li>
  <li> 요인행렬, 구조행렬, 패턴행렬  </li>
  <li> Reliability </li>


</mid>

<rig id="subRig">

  <h2> 분류분석 (회귀, 판별, 군집) </h2>

  <li> 회귀분석 : Linear Regression, Logistics </li>
  <li> 판별분석 : 집단평균의 동질성 검정, </li>
  <li> Wilks’ lamda, 정준판별함수, </li>
  <li> 고유값, 정준판별함수 계수, </li>
  <li> 분류함수계수  </li>


</rig>

<bot id="subBot">

  <h2> 통계 분석 : t 검정 </h2>
  <li> 일표본 : 하나의 표본에서 표본 내 여러 케이스를 1회 측정한 값으로 모집단의 평균을 검정하는 방법이며, 새로운 기계의 도입, 공정의 개선 및 혁신을 통해 기존과 다른 방식에 따른 결과가 기존의 값들과 차이가 있는 지에 대하여 확인하고자 할 때 사용 가능.
    The one-sample t-test is used to determine whether a sample comes from a population with a specific mean.
    This population mean is not always known, but is sometimes hypothesized.  </li>
    <li> SPSS ( 분석 / 평균비교 / 대응표본 t 검정 ) : 검정변수 선택, 검정값 결정 , 기술 통계량(평균, 분산 및 표준편차),
      일표본 통계량 , 일표본 검정 (t, 자유도, 유의확률) </li>


      <li> 대응표본 t 검정: 하나의 표본에서 여러 케이스를 이 전과 이후 2회 측정한 값을 이용 두 측정치 간의 차이 여부를 분석하다. 이 것은 조치 전과 후의 차이 변화에 대한 통계적 유의성 여부로 조치의 적정성을 판단하고자 하는 것이다. 동일한 집단에서 한 쌍의 측정값을 분석하는 것으로 다양한 케이스에 응용하여 사용할 수 있다.
        <li> SPSS ( 분석 / 평균비교 / 대응표본 t 검정 ) :   </li>

        <li> 독립표본 : 하나의 표본에서 여러 케이스를 이 전과 이후 2회 측정한 값을 이용 두 측정치 간의 차이 여부를 분석하다.
          이 것은 조치 전과 후의 차이 변화에 대한 통계적 유의성 여부로 조치의 적정성을 판단하고자 하는 것이다. 동일한 집단에서
          한 쌍의 측정값을 분석하는 것으로 다양한 케이스에 응용하여 사용할 수 있다. </li>
          <li>  SPSS ( 분석 / 평균비교 / 대응표본 t 검정 ) : 대응 표본 검정 결과(대응차, t, 유의확률)  </li>

        </br>

        <h2> 통계 분석 : 분산 분석  </h2>
        <li> one-way ANOVA : 독립변수가 1개 이면서 3개 이상의 표본일 때 집단 간 종속변수의 평균 차이를 검정하는 방법으로
          종속변수는 등간척도 혹은 비율척도로 구성된다.
          기본 가정으로 등분산 여부를 확인 :
        </li>


        <li>  독립변수의 수준에 따라서 집단 간 차이가 있다고 확인된 경우에는 집단 간 정확한 차이를 판별하기 위해 사후분석을 실시하며,
          등분산 가정 여부에 따라 적용하는 방법이
          사후분석 기법으로 Duncon (집단 분리의 성격이 강함), Tukey (집단별 관측치의 수가 동일한 경우 사용 ),
          Bouferroni (집단 수가 동일하며 분리 수준은 Tukey), Scheffe (보수적으로 소극적으로 집단 분리)
        </li>

        <li> 결과 해석 : 분산의 동질성 검정에서 유의확률(p value)가 0.05 보다 적을 경우 동질적인 것으로 판단한다.
          일원배치 분산분석에서 F값은 (집단 간 분산)/ (집단 내 분산) 이다.
          사후검정 결과의 다중비교를 통하여 집단 간의 평균 차이와 유의확률을 확인할 수 있다.
        </li>

        <li> SPSS ( 평균비교 / 일원배치 분산분석 : 사후분석은 일원분산분석을 통하여 집단 간 차이가 있다고 확인된 경우에 집단 간 정확한 차이를 판별하기 위해 실시한다.
          분산분석과 동시에 할 수도 있고, 유의성 확인 후에 별도로 할 수도 있다.
        </li>

        <li>   two-way ANOVA  : 독립변수가 2개일 때 집단 간 종속변수의 평균 차이를 검정하는 방법으로, 두 독립변수가 서로 연관되어 종속변수에 미치는
          상호효과 검정효과가 있는 지를 검정하는 방법이다.
        </li>

        <li>   SPSS : 분석 / 일반선형모형 / 일변량 </li>

        <li>  MANOVA , RM-ANOVA :  다변량 분석에서 여러가지 상황에 따라 분석의 신뢰성을 높일 수 있도록 적합한 방식을 선택하여 분석이 필요하다.
          관심을 갖지는 않는 변수 이지만 종속변수에 영향을 미칠 수 있는 경우이거나, 시간 간격을 두고 반복하여 측정하는 경우 및
          고정요인과
          공변량이 혼합되어 분석이 필요한 경우가 그렇다.</li>
          <li> ANCOVA : 종속변수, 고정요인, 공변량  (SPSS : 분석 / 일반선형모형 / 일변량),
            RM-ANOVA : (SPSS : 분석 / 반복측도 (시간), object간 요인 반복측도 ), Mixed Model :  (SPSS : 분석 / 개체 및 반복 분석 / 혼합모형 )
          </li>

          <li>   1개의 표본에서 관측된 값의 개수에 따라 z 분포표를 사용할 수도 있으며 대개 표본의 관측치가 30개 이상인 경우는 z 분포표를 사용하고
            그 이하인 경우는 t 분포표를 사용한다.
          </li>

          <br>

          <h2> 통계 분석 : 주성분 분석 ( PCA ) </h2>

          <li> 여러 독립변수들이 몇 개의 핵심 내재 요인으로 간추려져 전체 독립변수의 수를 줄이고 정보를 좀 더 쉽게 이해할 수 있도록 하며,
            간추려진 결과는 신뢰도 분석을 진행하여 신뢰도를 확인한 후에 회귀분석 단계로 진행할 수 있다.
          </li>

          <li> 방법은 변수들 간에 공분산과 상관계수를 토대로 고유값과 고유벡터를 활용하여 핵심 요인들을 찾는 방식이다.
          </li>

          <li> 요인분석은 주성분 분석과 공통요인 분석이 있으며, 주성분 분석은 요인간 독립성을 유지하여 회전하는 것으로 요인 간에는
            상관관계가 없다고 가정하고 분석하는 방법이다.
          </li>

          <li>  요인분석은 연구자가 모형을 만들면서 고려한 독립변수들의 타당성을 확인하는 방법으로 사용할 수 있는데,
            당초 연구자가 설정한 각 요인들로 해당하는 변수들이 함께 묶이지 않을 경우 해당 변수를 제외하거나 추가적인 작업을 실시하는 타당도 분석을 하게된다.
            결국 타당도 분석은 탐색적 요인분석을 이용하여 타당도를 확인하는 작업이다.
          </li>

          <li> 절차는 (SPSS : 분석 / 차원감소 / 요인분석) 기술통계 (KMO와 Bartlett의 구형성 검정),  요인추출 (방법 주성분),
            요인회전 (베리맥스),  요인점수 (변수로 저장)는 요인분석 결과로 변수로 저장한 값은 이후에 상관분석에 활용할 수 있다.
          </li>

          <li> 요인분석은 변수들 간의 동질성이나 유사한 속성을 가지고 묶는 것으로 변수들간의 상관분석을 통하여 상관관계가 높을 경우 하나의 요인으로 묶을 수 있다.
            따라서, 요인분석의 전체 진행 과정은 자료입력 -> 상관관계 분석 -> 요인추출 : 모델결정, 요인 수 결정 -> 요인적재량 산출->
            요인 회전 -> 요인 해석 -> 요인 점수 활용 단계를 거친다.
          </li>

          <li> 요인추출 모델 방법 : principal component, least square , maximum likelyhood, pricipal axis factoring, alpha factoring, image factoring  </li>

          <li> 결과 해석 : <br>

            기술통계/KMO와 Bartlett : 해당 변수로 요인분석을 하는 것이 적절한지를 확인하는 기준으로 KMO 는 변수들 간의 상관관계를 나타내는 것으로
            수치가 높을수록 상관 정도가 높으며, 사회 과학의 경우 최소 .5 이상이 되어야 한다. Bartlett 구형성 검정은 요인분석 모형의 적합성을 보는 것으로
            유의확률이 .05 이하가 되어야 적합하다. 적합모형에 대한 귀무가설은 상관관계 행렬이 단위행렬 이다.      </li>

            <li> 상관행렬/공통성 </li>

            <li> 설명된 총분산 (초기 고유값 - % 분산) : 초기 고유치는 요인이 설명하는 분산의 양으로 주요인이 있는 경우 몇 개의 주요인이 전체 분산의 상당수를 설명한다. 요인추출 시에 고유값 1 이상을
              설정한 경우 이 기준으로 추출한 값을 보여준다.
            </li>

            <li> 스크리 도표 : 요인 수 결정은 최소 고유값의 경우 고유값이 1 이상이면 의미가 있는 것으로 보며, 스크리 검정의 경우 고유값이 급격히 하락을 하다가
              완만하게 하락의 추세가 바뀌는 지점에서 요인의 수를 결정한다.
            </li>

            <li> 성분행렬 / 회전된 성분행렬 : 각 변수와 요인들간에 상관관계 정도를 요인 적재값(Factor loading)으로
              보여주는 것으로, 각 변수들은 요인 적재량이 높은 요인들에 속하게 된다.
              이 결과는 요인회전에서 선택한 방법에 의해 계산된 결과이다.
            </li>

            <li>공통성(Communality) : 추출된 요인들에 의해 설명되는 비율 </li>

            <li> 성분점수 공분산 행렬 : 직각회전 방법인 베리멕스를 사용한 경우 직각회전 방법은 각 요인들이 서로 독립적이라는 기본 가정으로 계산하기 때문에
              공분산이 모두 0으로 처리된다.
            </li>


          </br>

          <h2> 통계 분석 : 공통 요인분석 ( FA )  </h2>

          <li> 공통요인 분석은 자료의 축소라는 차원을 포함하면서 자료 내재적으로 존재하는 속성까지 찾아내는 방법으로, 변수 간 공통 요인을 추출하여
            변수간 상관관계를 찾고 각 변수의 성질을 축소한다.
          </li>

          <li> 절차는 ( SPSS : 분석 / 차원감소 / 요인분석 ) 주성분 분석과 요인 회전에서 차이가 있다.  </li>

          <li>         요인회전은 상관계수를 의미하는 요인 적재값을 통해 차원을 축소하게 되는데 공통요인 분석에서는 사각회전 방식을 사용한다.
            주성분 분석과 공통요인 분석은 서로 다른 개념이지만 공통성이 .6 이상이거나
            변수가 많아지면 두가지 분석결과의 해석은 같아지게 된다.
          </li>

          <li> 요인적재값 자체로는 변수간 상관관계를 확인하는데 한계가 있어, 요인회전을 통해 요인 적재값이 큰 경우는 더 확대하고,
            적은 경우는 더 작게하여 변수를 명확히 구분한다.
          </li>

          <li>   방법으로 직각회전과 사각회전이 있으며 기본 가정이 완전히 다르다.
            직각회전은 요인간 독립성을 유지하여 회전하는 것으로 요인 간에는 상관관계가 없다고 가정하는 것이다.

          </li>

          <li> 직각회전방법의 종류에는 베리맥스, 쿼티맥스, 이퀴맥스가 있다.
            사각회전은 요인간 연관관계를 유지하여 회전하는 것으로 종류는 직접 오블리민, 프로맥스가 있다.
          </li>

          <li>요인행렬 : 이 표의 요인적재값은 요인들과 변수들 간의 상관계수를 나타낸다. </li>

          <li> KMO와 Bartlett : 해당 변수로 요인분석을 하는 것이 적절한지를 확인하는 기준으로 KMO 는 변수들 간의 상관관계를 나타내는 것으로
            수치가 높을수록 상관 정도가 높으며, 사회 과학의 경우 최소 .5 이상이 되어야 한다. Bartlett 구형성 검정은 요인분석 모형의 적합성을 보는 것으로
            유의확률이 .05 이하가 되어야 적합하다. 적합모형에 대한 귀무가설은 상관관계 행렬이 단위행렬 이다.
          </li>
          <li>설명된 총분산 : 초기 고유치는 요인이 설명하는 분산의 양으로 주요인이 있는 경우 몇 개의 주요인이 전체 분산의 상당수를 설명한다. 요인추출 시에 고유값 1 이상을
            설정한 경우 이 기준으로 추출한 값을 보여준다.
          </li>
            <li>공통성(Communality) : 추출된 요인들에 의해 설명되는 비율 </li>
            <li>회전된 성분행렬 : 각 변수와 요인들간에 상관관계 정도를 요인 적재값(Factor loading)으로 보여주는 것으로, 각 변수들은 요인 적재량이 높은 요인들에 속하게 된다.
              이 결과는 요인회전에서 선택한 방법에 의해 계산된 결과이며다.
            </li>
            <li>성분행렬 : 요인회전을 할 때 사용된 행렬값 </li>
            <li>성분점수 공분산 행렬 : 직각회전 방법인 베리멕스를 사용한 경우 직각회전 방법은 각 요인들이 서로 독립적이라는 기본 가정으로 계산하기 때문에
              공분산이 모두 0으로 처리된다.
            </li>
            <li>요인분석 결과로 인한 요인점수를 변수로 저장한 값은 이후에 상관분석에 활용할 수 있다.    </li>
            <li>적합도 검정 : 변수들이 독립적인지 여부를 확인하는 것으로 유의확률이 .05 이하면 귀무가설을 기각하여 변수들이 독립적인 관계가 아니다.
              변수들 간에 상관관계가 있다라는 의미이며, 이 값은 카이제곱 검정을 통해 진행된 것이다.
            </li>
            <li> 패턴행렬 : 직각회전의 회전된 성분행렬표와 같은 것으로 일반적으로 .3 이상이면 추출된 요인이 통계적으로 의미가 있다고 판단하며,
              .5 이상이면 매우 유의한 것으로 판단한다.    </li>

              <li> 직각회전 방법과 다른 분석결과는 패턴행렬과 구조행렬이 있다.          </li>




            </br>

            <h2> 통계 분석 : Reliability / Correlation  </h2>
            <li>   Reliability :


              <li>   Correlation :   Pearson's correlation , Spearman's correlation , 교차 분석 , 편상관 분석     </li>


              <br>


            </br>


            <h2> 통계 분석 : 회귀 분석  </h2>

            <li>  회귀분석은 더미변수를 명목척도로 사용하는 경우를 제외하고독립변수, 종속변수 모두 등간, 비율척도로 구성된다.




              <h2> 통계 분석 : 판별, 군집 분석  </h2>

              <li>  판별분석은 2개 이상의 집단에 대하여 설명변수를 이용하여 집단을 구분할 수 있도록 하며, 독립변수는
                등간척도, 비율척도이며 종속변수는 명목척도로 구성이 된다.
              </li>
              <li> 집단 내 분산에 비해 집단간 분산의 차이를 크게할 수 있는 독립변수들의 계수를 찾는 것으로 독립변수들의 선형결합을
                판별함수라고 한다.
              </li>
              <li> 판별분석의 경우 다변량 정규분포이며 종속변수의 그룹들의 분산 공분산 구조행렬이 동일하다는 기본 가정을 충족하여야 한다.
                집단이 2개 이면서 이 기본가정을 충족하기 어려울 경우 로지스틱 회귀분석을 이용 집단을 분류할 수 있다.
              </li>
              <li> 판별함수의 수는 (종속변수 집단 수 – 1)과 독립변수 수 중에서 작은 수 만큼의 판별함수가 만들어지며,
                판별분석의 표본의 크기는 관측치의 개수(표본의 크기)가 독립변수 수의 20배 이상이 되도록 요구되며,
                종속변수의 각 범주에 최소한 20개가 요구하며, 표본의 크기가 이를 충족시키지 못하면 분석결과는 불안정하게 된다.
              </li>
              <li> 판별식을 구성하는 각 독립변수와 전체 판별식의 설명력과 예측력을 신뢰할 수 없다는 의미가 된다.

              </li>
              <li> 판별식의 추정과 적합도 평가 방법은 두가지 방식이 사용된다. 동시입력방식(simultaneous estimation) : 모든 독립변수들에 대한 계수 동시에 계산.
                단계입력방식(stepwise estimation) : 판별력이 높은 순서로 입력되어 추정이 이루어진다.
              </li>
              <li>   * SPSS : 분석 / 분류분석 / 판별분석 :  집단 변수 (그룹으로 구분되는 변수), 집단 변수의 범위 지정(최소~최대)
              </li>

            <li> 집단평균의 동질성에 대한 검정(Wilks 람다, 유의확률) :  판별함수의 판별력(discriminatory power)의 통계적 유의성 점검은 Wilks’ lamda가 주로 사용되며, χ2검증을 실시한다.
              판별함수의 전반적 적합도(overall fit) 점검시에 판별함수의 판별력은 유의적으로 나타나더라도
              집단의 수와 함께 고려하여야 한다. 두 집단의 경우 hit ratio가 50% 조금 넘기는 수준일 경우 판별력이 좋다고 할 수 없다.
              이는 두 집단의 크기가 같은 경우 임의적 분류를 하더라도 hit ratio는 50%이기 때문이다.
            </li>

            <li> 집단평균의 동질성에 대한 검정(Wilks 람다, 유의확률) : 집단내 분산/(집단내 분산 + 집단간 분산)의 비율로서 집단간 분산이 집단내 분산에 비해 클수록 0에 가까워지며,
              반대의 경우 1에 가까워지고 분산분석의 F값과는 반대방향을 갖는다.
               종속변수에 대하여 각 변수들의 유의확률을 확인하여 통계적으로 유의한 지를 확인한다.
            </li>

            <li> 집단 내 통합행렬 / 공분산행렬 </li>
            <li> 공분산행렬에 대한 Box의 검정 (로그 행렬식 / 검정 결과) : 공분산 행렬과 Box’s M-검증으로
              공분산 행렬의 동일성 가정에 위배되는지 확인하는 것으로 검정결과표(Box의 M, F)의 유의확률이 .05 보다 클 경우 동일하다고 간주한다.
            </li>
            <li> 정준판별함수의 요약 : Wilks’ lamda 값의 χ2-검증결과 p-value이 .05 보다 작으면 집단간에 유의적이 차이가 있으며,
              판별함수가 유용함을 나타낸다.
            </li>
            <li>고유값 (고유값 - 정준상관) : 정준상관 관계는 정준판별함수(Canonical Discriminant Function)와 집단간의 상관관계를 나타내는
              것으로, 이 값이 클수록 판별력이 우수하다. * 정준상관계수(canonical correlation coefficient) 를
              제곱하면  설명력을 나타내는 값으로 이는 종속변수 분산의 해당 값의 %가 독립변수들에 의해 설명됨을 의미한다.
            </li>
            <li> 고유값은 집단간의 분산을 집단 내의 분산으로 나눈 값으로 고유값이 클수록 우수한 판별함수라고 할 수있다.
              Wilks의 람다 : 람다값이 작을수록 판별함수의 설명력은 높아진다.
            </li>
            <li> 표준화 정준판별함수 계수(standardized canonical discriminant function coefficient) : 표준화된 계수로서 각 변수가
              소속집단을 설명하는데 있어서 상대적 중요도를 나타내며, 판별함수식의 Wi값을 표준화 한 것이다.
            </li>

            <li> 정준판별함수 계수와 구조행렬 : 독립변수의 판별력을 보여주는데 구조행렬상에 있는 계수(판별적재값)가 많이 사용되며,
              계수값이 클수록 판별력이 크다.
            </li>
            <li> 구조행렬(structure matrix) : 각 변수와 표준화된 정준판별함수간의 상관관계를 나타내며, 값이 높을수록 판별점수도 높아진다.
              상관관계 값은 판별적재값(discriminant loading)이라고도 하며, 요인분석의 요인적재값에 비유될 수 있다.
            </li>
            <li> 판별력을 위해 전통적으로 표준화된 판별계수를 이용하였으나, 다중회귀분석의 경우와 유사하게
              각 변수의 판별력이 다중공선성(multicollinearity)으로 낮게 나타날 수 있어 판별력의 크기는 구조행렬로 판단한다.
              판별적재값은 ± .3 이상이면 유의적인 것으로 본다.
            </li>
            <li>정준판별함수 계수: 표준화되지 않은 정준판별함수계수(unstandardized discriminant function coefficient)이며,
              회귀분석의 회귀계수 처럼 판별함수식의 Wi값이며, 판별점수(Z)를 계산하는데 사용한다.
              상대적인 중요성을 판단하는데 사용해서는 안된다.
            </li>
            <li>함수의 집단 중심점 : 정준판별함수의 판별식에 의한 판별점수가 이 분류기준보다 크거나 작느냐에 따라 분류가 된다.
              집단 중심점은 각 집단에 속한 판별점수를 구하고 이 값들의 평균으로 각 집단의 중심값(centroid)이다.
            </li>
            <li> 새로운 관측치가 있으면 정준판별 함수계수를 이용 값을 구하고 이 값과 중심값(centroid)을 비교하여 해당 집단을 판별한다.   </P>
            </li>

            <li> 분류 통계량 : 분류처리 요약 / 집단에 대한 사전확률 / 분류함수계수 /케이스별 통계량 </li>
          </li>
          <li> 분류함수계수 : 분류함수(classification function) 또는 Fisher’s 선형판별함수(linear discriminant function)는
            각 집단별로 생성되며(집단의 수만큼 생성), 새로운 분류대상이 있을 때 그 분류대상의 독립변수 값들을 분류함수에 삽입하여 계산한
            결과 큰 값으로 나타나는 집단에 분류된다.
          </li>
          <li> 분류 결과 : 판별한 결과를 정리한 표,  분류함수와 정준판별함수의 구별 :
            <p>  분류함수 : 집단의 수만큼 도출되며, 새로운 관측값을 대입하여 어느 집단에 분류될 것인지를 예측하는데 사용한다,
              정준판별함수 : (집단의 수 – 1)과 (독립변수의 수) 중에서 작은 수만큼 도출되며,
                기존 분석의 대상이 된 관측값들이 소속된 각 집단의 중심값(cetroid)을 계산하는데 사용.  </p>

              </li>

              <li> Hit Ratio : 판별함수가 조사대상을 얼마나 잘 분류할 수 있는가를 나타내며, 회귀분석의 R2에 비유될 수 있다.   </li>

              <li>Reference Site </li>

              <a href="https://www.ibm.com/support/knowledgecenter/ko/SSLVMB_25.0.0/statistics_mainhelp_ddita/spss/base/idh_disc.html "> 판별분석에 대한 IBM 설명 </a>
              <P> 판별 분석은 그룹소속에 대한 예측 모형을 작성합니다. 모형은 프로시저로 그룹 간에 가장 큰 차별을 나타내는 예측변수의 선형 조합을
                기본으로 하는 판별 함수(그룹이 셋 이상인 경우 판별 함수 세트)로 구성되어 있습니다. 이러한 함수는
                해당 소속그룹이 알려진 케이스 표본으로부터 작성되며 해당 소속그룹은 알 수 없으나 예측변수 측정을 통해 새로운 케이스에
                적용될 수는 있다. </P>


                <h2> Linear Regression </h2>

                <li>   Linear Regression : Simple Linear Regression , Multiple Linear Regression ,
                  Dummy Linear Regression
                </li>

                <li>  Hierarchical analysis </li>
                <li>  Logistics Regression , Mediation Regressions , Logistics Regression , Moderator Regressions </li>

                <li>  Discriminant Analysis </li>

                <li>Clustering Analysis , hierarchical Clustering, k-means Clustering </li>
                <li> Theory  </li>
                <li>Tool  </li>
                <li>Template  </li>
                <li>Reference Site </li>


                <h2>Theory, Tool & Template</h2>


                <li>Tool  </li>
                <li>Template  </li>
                <li>Reference Site </li>
                <p>
                </p>



              </bot>

            </body>

            </html>
